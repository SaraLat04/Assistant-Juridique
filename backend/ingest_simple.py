"""
Script d'ingestion CSV simplifi√©
ChromaDB g√©n√®re les embeddings automatiquement
"""

import os
import pandas as pd
import uuid
import re
from services.vector_db import init_chroma, reset_chroma

# =======================
# üìÇ Fonctions de chargement
# =======================

def load_csv(file_name):
    """Charge un fichier CSV"""
    if os.path.exists(file_name):
        df = pd.read_csv(file_name, encoding='utf-8')
        print(f"‚úÖ Fichier charg√© : {file_name} ({len(df)} lignes)")
        return df
    else:
        raise FileNotFoundError(f"‚ùå {file_name} introuvable !")


def preprocess_csv(df, file_name):
    """Pr√©traite le DataFrame pour standardiser les colonnes"""
    # Nettoyer les noms de colonnes
    df.columns = [col.strip().lower() for col in df.columns]
    
    # Mapper les colonnes vers un format standard
    col_mapping = {
        'doc': 'DOC', 
        'titre': 'Titre', 
        'chapitre': 'Chapitre',
        'section': 'Section', 
        'article': 'Article',
        'contenu': 'Contenu', 
        'texte': 'Contenu', 
        'pages': 'Pages'
    }
    
    df = df.rename(columns={col: col_mapping.get(col, col) for col in df.columns})
    
    # Ajouter les colonnes manquantes
    for col in ['DOC', 'Titre', 'Chapitre', 'Section', 'Article', 'Contenu', 'Pages']:
        if col not in df.columns:
            df[col] = ''
    
    # Cr√©er le texte complet
    df['texte_complet'] = df['Article'].fillna('') + ' ' + df['Contenu'].fillna('')
    df['texte_complet'] = df['texte_complet'].str.replace('\r\n', ' ').str.strip()
    
    print(f"‚úÖ Pr√©traitement termin√© : {len(df)} entr√©es")
    return df


def chunk_text(text, max_chars=1000):
    """D√©coupe un texte long en chunks plus petits"""
    sents = re.split(r'(?<=[.!?])\s+', text.strip())
    chunks, chunk = [], ""
    
    for sent in sents:
        if len(chunk) + len(sent) < max_chars:
            chunk += " " + sent
        else:
            if chunk.strip():
                chunks.append(chunk.strip())
            chunk = sent
    
    if chunk.strip():
        chunks.append(chunk.strip())
    
    return chunks


def prepare_chunks(df, source_name):
    """Pr√©pare les chunks pour l'ingestion dans ChromaDB"""
    texts, metadatas, ids = [], [], []
    
    for idx, row in df.iterrows():
        content = str(row['texte_complet']).strip()
        
        if not content or content == 'nan':
            continue
        
        # D√©couper si trop long
        chunks = chunk_text(content) if len(content) > 1000 else [content]
        
        for i, chunk in enumerate(chunks):
            texts.append(chunk)
            metadatas.append({
                'source': source_name,
                'doc': str(row['DOC']),
                'article': str(row['Article']),
                'pages': str(row['Pages']),
                'titre': str(row['Titre']),
                'chunk_id': i
            })
            ids.append(str(uuid.uuid4()))
    
    print(f"‚úÖ {len(texts)} chunks cr√©√©s depuis {source_name}")
    return texts, metadatas, ids


# =======================
# üöÄ Fonction principale d'ingestion
# =======================

def ingest_csv_files(csv_files: list, reset: bool = False):
    """
    Ing√®re plusieurs fichiers CSV dans ChromaDB
    ChromaDB g√©n√®re les embeddings automatiquement
    
    Args:
        csv_files: Liste de chemins vers les fichiers CSV
        reset: Si True, r√©initialise la base avant l'ingestion
    """
    print("\n" + "="*60)
    print("üöÄ D√âMARRAGE DE L'INGESTION DES DOCUMENTS JURIDIQUES")
    print("="*60 + "\n")
    
    # Initialiser ou r√©initialiser ChromaDB
    if reset:
        print("üîÑ R√©initialisation de ChromaDB...")
        client, collection = reset_chroma()
    else:
        client, collection = init_chroma()
    
    # Traiter chaque fichier CSV
    all_texts, all_metadatas, all_ids = [], [], []
    
    for csv_file in csv_files:
        print(f"\nüìÑ Traitement de : {csv_file}")
        print("-" * 60)
        
        try:
            # Charger et pr√©traiter
            df = load_csv(csv_file)
            df = preprocess_csv(df, csv_file)
            
            # Extraire le nom du fichier comme source
            source_name = os.path.basename(csv_file).replace('.csv', '')
            
            # Pr√©parer les chunks
            texts, metadatas, ids = prepare_chunks(df, source_name)
            
            all_texts.extend(texts)
            all_metadatas.extend(metadatas)
            all_ids.extend(ids)
            
        except Exception as e:
            print(f"‚ùå Erreur avec {csv_file} : {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # V√©rifier qu'on a des donn√©es
    if not all_texts:
        print("\n‚ùå Aucun document √† ing√©rer !")
        return
    
    print(f"\nüìä TOTAL : {len(all_texts)} chunks √† ing√©rer")
    
    # Ins√©rer dans ChromaDB par batches
    # ChromaDB va g√©n√©rer les embeddings automatiquement
    print("\nüíæ Insertion dans ChromaDB (embeddings auto)...")
    batch_size = 100  # Batch plus petit pour √©viter les timeouts
    
    for i in range(0, len(all_texts), batch_size):
        end = min(i + batch_size, len(all_texts))
        
        print(f"   üîÑ Batch {i//batch_size + 1} : traitement de {i} √† {end}...", end='')
        
        collection.add(
            ids=all_ids[i:end],
            documents=all_texts[i:end],
            metadatas=all_metadatas[i:end]
            # Pas d'embeddings ‚Üí ChromaDB les g√©n√®re automatiquement
        )
        
        print(f" ‚úÖ")
    
    # R√©sum√© final
    print("\n" + "="*60)
    print("‚úÖ INGESTION TERMIN√âE AVEC SUCC√àS !")
    print("="*60)
    print(f"üìä Total documents dans ChromaDB : {collection.count()}")
    print(f"üíæ Stockage : {os.path.abspath('chroma_db/')}")
    print("\nüí° Testez maintenant :")
    print("   python test_chroma.py")
    print("   python app.py")


# =======================
# üéØ Script principal
# =======================

if __name__ == "__main__":
    # üìÇ Rechercher automatiquement tous les CSV dans data/
    data_dir = "data"
    
    if os.path.exists(data_dir):
        csv_files = [
            os.path.join(data_dir, f) 
            for f in os.listdir(data_dir) 
            if f.endswith('.csv')
        ]
    else:
        csv_files = []
    
    if not csv_files:
        print("\n‚ùå AUCUN FICHIER CSV TROUV√â !")
        print("\nüí° Cr√©ez un dossier 'data/' et placez-y vos fichiers CSV")
        print("\nFormat attendu des colonnes :")
        print("   - doc ou DOC : Nom du document (ex: 'Code P√©nal')")
        print("   - article ou Article : Num√©ro de l'article (ex: 'Article 392')")
        print("   - contenu ou Contenu : Texte de l'article")
        print("   - titre ou Titre : Titre du chapitre (optionnel)")
        print("   - pages ou Pages : Num√©ro de pages (optionnel)")
        print("\nExemple de structure CSV :")
        print("   DOC,Article,Contenu")
        print('   "Code P√©nal","Article 392","Est puni de la r√©clusion..."')
        print(f"\nüìÅ Cr√©ez le dossier : {os.path.abspath(data_dir)}/")
        
        # Cr√©er un exemple de fichier CSV
        print("\nüí° Cr√©ation d'un fichier CSV d'exemple...")
        os.makedirs(data_dir, exist_ok=True)
        
        example_csv = os.path.join(data_dir, "exemple_test.csv")
        with open(example_csv, 'w', encoding='utf-8') as f:
            f.write('DOC,Article,Contenu\n')
            f.write('"Code P√©nal Marocain","Article 392","Est puni de la r√©clusion de cinq √† dix ans, quiconque commet un vol dans les circonstances suivantes : lorsque le vol est commis avec violence ou menace de violence."\n')
            f.write('"Code de la Famille","Article 4","Le mariage est un contrat l√©gal par lequel un homme et une femme s\'unissent en vue d\'une union l√©gale et durable."\n')
            f.write('"Code du Travail","Article 6","Est consid√©r√© comme salari√© toute personne qui s\'est engag√©e √† exercer son activit√© professionnelle sous la direction d\'un ou plusieurs employeurs moyennant r√©mun√©ration."\n')
        
        print(f"‚úÖ Fichier cr√©√© : {example_csv}")
        print("\nüîÑ Relancez le script pour ing√©rer ce fichier d'exemple")
        
    else:
        print(f"\n‚úÖ {len(csv_files)} fichier(s) CSV trouv√©(s) dans {data_dir}/")
        print("\nFichiers √† ing√©rer :")
        for f in csv_files:
            size = os.path.getsize(f) / 1024  # Taille en Ko
            print(f"   - {f} ({size:.1f} Ko)")
        
        # Demander confirmation
        print("\n" + "="*60)
        reset_input = input("üîÑ R√©initialiser ChromaDB avant l'ingestion ? (o/n) : ").strip().lower()
        reset = reset_input == 'o'
        print("="*60)
        
        # Lancer l'ingestion
        try:
            ingest_csv_files(csv_files, reset=reset)
        except Exception as e:
            print(f"\n‚ùå Erreur : {e}")
            import traceback
            traceback.print_exc()